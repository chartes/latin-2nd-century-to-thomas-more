{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "import regex\n",
    "\n",
    "def roman_number(inp: str) -> int:\n",
    "    \"\"\"\n",
    "    Source: https://stackoverflow.com/questions/19308177/converting-roman-numerals-to-integers-in-python\n",
    "    Author: https://stackoverflow.com/users/1201737/r366y\n",
    "    :param num:\n",
    "    :return:\n",
    "\n",
    "    >>> roman_number(\"XXIV\")\n",
    "    24\n",
    "    \"\"\"\n",
    "    roman_numerals = {'I': 1, 'V': 5, 'X': 10, 'L': 50, 'C': 100, 'D': 500, 'M': 1000}\n",
    "    result = 0\n",
    "    for i, c in enumerate(inp.upper()):\n",
    "        if (i+1) == len(inp) or roman_numerals[c] >= roman_numerals[inp[i+1]]:\n",
    "            result += roman_numerals[c]\n",
    "        else:\n",
    "            result -= roman_numerals[c]\n",
    "    return result\n",
    "\n",
    "def uvji(val):\n",
    "    return val.replace(\"V\", \"U\").replace(\"v\", \"u\").replace(\"J\", \"I\").replace(\"j\", \"i\")\n",
    "\n",
    "def get_tasks(morph):\n",
    "    return dict([\n",
    "        m.split(\"=\") \n",
    "        for m in morph.split(\"|\")\n",
    "    ])\n",
    "\n",
    "# Useful constants\n",
    "\n",
    "WRONG_CLITICS = {\"quis1\"}\n",
    "DOTS_EXCEPT_APOSTROPHES = r\".?!\\\"“”\\\"«»…\\[\\]\\(\\)„“\"\n",
    "TASKS = \"form,lemma,Deg,Numb,Person,Mood_Tense_Voice,Case,Gend,Dis,pos\".split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clitics = []\n",
    "files = {\n",
    "    \n",
    "}\n",
    "\n",
    "with open(\"latin-chretien-v2.tsv\") as f:\n",
    "    header = []\n",
    "    cur_text = None\n",
    "    previous_anno = None\n",
    "    anno = None\n",
    "    for lineno, line in enumerate(f):\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        if lineno == 0:\n",
    "            header = line\n",
    "            continue\n",
    "            \n",
    "        previous_anno = anno\n",
    "        anno = dict(zip(header, line))\n",
    "        if anno[\"form\"].startswith(\"urn:\"):\n",
    "            cur_text = anno[\"form\"]\n",
    "            files[anno[\"form\"]] = []\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        if anno[\"form\"] in DOTS_EXCEPT_APOSTROPHES:\n",
    "            if files[cur_text][-1] != {}:\n",
    "                files[cur_text].append({})\n",
    "            continue\n",
    "            \n",
    "        anno[\"Dis\"] = \"_\"\n",
    "        \n",
    "        anno.update(get_tasks(anno[\"morph\"]))\n",
    "        anno[\"Mood_Tense_Voice\"] = \"|\".join([\n",
    "            anno.get(part, \"_\")\n",
    "            for part in \"Mood_Tense_Voice\".split(\"_\")\n",
    "        ]).replace(\"_|_|_\", \"_\")\n",
    "        \n",
    "        \n",
    "        if anno[\"lemma\"].isnumeric():\n",
    "            if int(anno[\"lemma\"]) > 3:\n",
    "                anno[\"lemma\"] = anno[\"form\"] = \"3\"\n",
    "                \n",
    "        if anno[\"lemma\"][-1].isnumeric() and len(anno[\"lemma\"]) > 1:\n",
    "            anno[\"lemma\"], anno[\"Dis\"] = anno[\"lemma\"][:-1], anno[\"lemma\"][-1]\n",
    "            \n",
    "        if anno[\"lemma\"] == \"[ROMAN_NUMBER]\":\n",
    "            anno[\"lemma\"] = anno[\"form\"] = roman_number(anno[\"form\"])\n",
    "            if anno[\"lemma\"] > 3:\n",
    "                anno[\"lemma\"] = anno[\"form\"] = \"3\"\n",
    "        \n",
    "        if anno[\"lemma\"] == \"[Greek]\":\n",
    "            continue\n",
    "            \n",
    "        if anno[\"POS\"] == \"OUT\":\n",
    "            print(anno)\n",
    "            \n",
    "        if anno[\"POS\"] == \"PUNC\":\n",
    "            continue\n",
    "            \n",
    "        if anno[\"POS\"] == \"VERaux\":\n",
    "            anno[\"POS\"] = \"VER\"\n",
    "            \n",
    "        if len(files[cur_text]) and files[cur_text][-1] and files[cur_text][-1] == previous_anno \\\n",
    "            and files[cur_text][-1][\"form\"] == anno[\"form\"]:\n",
    "            if anno[\"lemma\"] not in WRONG_CLITICS:\n",
    "                clitics.append(anno[\"lemma\"])\n",
    "                files[cur_text][-1][\"lemma\"] = files[cur_text][-1][\"lemma\"]+\"界\"+anno[\"lemma\"]\n",
    "                continue\n",
    "        \n",
    "        anno[\"lemma\"] = uvji(anno[\"lemma\"])\n",
    "        anno[\"form\"] = uvji(anno[\"form\"])\n",
    "        \n",
    "        if \".\" in anno[\"form\"]:\n",
    "            print(anno)\n",
    "        \n",
    "        if True and anno[\"POS\"].startswith(\"NOM\"):\n",
    "            anno[\"POS\"] = \"NOM\"\n",
    "        anno[\"pos\"] = anno[\"POS\"]\n",
    "        \n",
    "        files[cur_text].append(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urn:cts:latinLit:stoa0275.stoa022.opp-lat1:3 has 558 tokens and 36 sentences\n",
      "urn:cts:latinLit:stoa0275.stoa027.opp-lat2:9-10 has 621 tokens and 36 sentences\n",
      "urn:cts:latinLit:stoa0040.stoa003.opp-lat4:17.4 has 2467 tokens and 128 sentences\n",
      "urn:cts:latinLit:stoa0040.stoa011.opp-lat4:262.1-262.4 has 571 tokens and 17 sentences\n",
      "urn:cts:latinLit:stoa0270.stoa002.opp-lat2:9-10 has 503 tokens and 27 sentences\n",
      "urn:cts:latinLit:stoa0238.stoa002.perseus-lat2:pr.1-1.20 has 464 tokens and 15 sentences\n",
      "urn:cts:latinLit:stoa0096.stoa003.opp-lat2:1.35-1.37 has 411 tokens and 42 sentences\n",
      "urn:cts:latinLit:stoa0104a.stoa010.opp-lat1:6-8 has 654 tokens and 31 sentences\n",
      "urn:cts:latinLit:stoa0249a.stoa002.opp-lat1:6.53-6.60 has 527 tokens and 25 sentences\n",
      "urn:cts:latinLit:stoa0076c.stoa002.opp-lat2:8.8-8.10 has 540 tokens and 17 sentences\n",
      "urn:cts:latinLit:stoa0022.stoa044.opp-lat1:1-8 has 555 tokens and 35 sentences\n",
      "urn:cts:latinLit:stoa0054.stoa001a.opp-lat1:1-2 has 928 tokens and 40 sentences\n",
      "urn:cts:latinLit:stoa0149b.stoa001.opp-lat1:2 has 8340 tokens and 393 sentences\n",
      "urn:cts:latinLit:stoa0171.stoa002.opp-lat1:26-27 has 561 tokens and 31 sentences\n",
      "urn:cts:latinLit:stoa0162.stoa024.opp-lat1:1.1.1-1.2.3 has 502 tokens and 21 sentences\n",
      "urn:cts:latinLit:stoa0058.stoa023.perseus-lat1:3 has 625 tokens and 30 sentences\n",
      "urn:cts:latinLit:stoa0143.stoa001:@.30-2.31 has 551 tokens and 29 sentences\n",
      "urn:cts:latinLit:stoa0261.stoa002:4.3 has 726 tokens and 26 sentences\n",
      "urn:cts:latinLit:stoa0112.stoa001:1-3 has 628 tokens and 20 sentences\n",
      "['que', 'que', 'que', 'que', 'cum', 'que', 'que', 'ne', 'ne', 'que', 'que', 'que', 'que', 'cum', 'que', 'cum', 'cum', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'cum', 'cum', 'cum', 'cum', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'cum', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'cum', 'que', 'que', 'que', 'ue', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'cum', 'cum', 'que', 'que', 'as', 'que', 'que', 'cum', 'que', 'que', 'que', 'que', 'quis', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'ue', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'que', 'cum', 'que']\n"
     ]
    }
   ],
   "source": [
    "# Write\n",
    "        \n",
    "with open(\"lasla-model-ready.tsv\", \"w\") as full:\n",
    "    full.write(\"\\t\".join(TASKS)+\"\\n\")\n",
    "    for file in files:\n",
    "        print(f\"{file} has {len([an for an in files[file] if an])} tokens \"\n",
    "              f\"and {len([an for an in files[file] if not an])} sentences\")\n",
    "        with open(f\"lasla-model-ready/{file}.tsv\", \"w\") as f:\n",
    "            f.write(\"\\t\".join(TASKS)+\"\\n\")\n",
    "            for annot in files[file]:\n",
    "                if not annot:\n",
    "                    f.write(\"\\n\")\n",
    "                    continue\n",
    "                f.write(\"\\t\".join([annot.get(h, \"_\") for h in TASKS])+\"\\n\")\n",
    "                full.write(\"\\t\".join([annot.get(h, \"_\") for h in TASKS])+\"\\n\")\n",
    "    full.write(\"\\n\")\n",
    "print(clitics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
